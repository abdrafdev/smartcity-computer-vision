{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèôÔ∏è Smart City Computer Vision - Data Analysis\n",
    "\n",
    "This notebook provides data analysis and visualization tools for the Smart City Computer Vision project.\n",
    "\n",
    "## üìã Contents\n",
    "1. Dataset Statistics\n",
    "2. Model Performance Analysis  \n",
    "3. Inference Results Visualization\n",
    "4. Class Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append('..')\n",
    "from utils.common import count_dataset_files, get_class_names\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('default')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze dataset statistics for all models\n",
    "models = ['garbage', 'helmet', 'traffic']\n",
    "dataset_stats = {}\n",
    "\n",
    "for model in models:\n",
    "    dataset_path = f'../{model}-detection/data'\n",
    "    if os.path.exists(dataset_path):\n",
    "        stats = count_dataset_files(dataset_path)\n",
    "        dataset_stats[model] = stats\n",
    "        print(f\"üìÅ {model.title()} Detection Dataset:\")\n",
    "        for split, count in stats.items():\n",
    "            print(f\"  {split}: {count} images\")\n",
    "        print(f\"  Total: {sum(stats.values())} images\\n\")\n",
    "\n",
    "# Create visualization\n",
    "if dataset_stats:\n",
    "    df = pd.DataFrame(dataset_stats).T\n",
    "    df.plot(kind='bar', figsize=(10, 6), title='Dataset Distribution by Model Type')\n",
    "    plt.ylabel('Number of Images')\n",
    "    plt.xlabel('Model Type')\n",
    "    plt.legend(title='Split')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Class Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze class distributions\n",
    "def analyze_labels(model_name):\n",
    "    \"\"\"Analyze label distribution for a given model.\"\"\"\n",
    "    labels_dir = f'../{model_name}-detection/data/train/labels'\n",
    "    \n",
    "    if not os.path.exists(labels_dir):\n",
    "        print(f\"Labels directory not found: {labels_dir}\")\n",
    "        return None\n",
    "    \n",
    "    class_counts = {}\n",
    "    total_objects = 0\n",
    "    \n",
    "    for label_file in glob.glob(os.path.join(labels_dir, '*.txt')):\n",
    "        with open(label_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                if line.strip():\n",
    "                    class_id = int(line.split()[0])\n",
    "                    class_counts[class_id] = class_counts.get(class_id, 0) + 1\n",
    "                    total_objects += 1\n",
    "    \n",
    "    return class_counts, total_objects\n",
    "\n",
    "# Analyze each model\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for idx, model in enumerate(models):\n",
    "    result = analyze_labels(model)\n",
    "    if result:\n",
    "        class_counts, total = result\n",
    "        class_names = get_class_names(model)\n",
    "        \n",
    "        # Convert to readable names\n",
    "        readable_counts = {}\n",
    "        for class_id, count in class_counts.items():\n",
    "            name = class_names.get(class_id, f'Class_{class_id}')\n",
    "            readable_counts[name] = count\n",
    "        \n",
    "        # Create bar plot\n",
    "        ax = axes[idx]\n",
    "        classes = list(readable_counts.keys())\n",
    "        counts = list(readable_counts.values())\n",
    "        \n",
    "        ax.bar(classes, counts)\n",
    "        ax.set_title(f'{model.title()} Detection\\nTotal Objects: {total}')\n",
    "        ax.set_ylabel('Count')\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Model Performance Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and visualize training results\n",
    "def plot_training_results(model_name):\n",
    "    \"\"\"Plot training results from results.png if available.\"\"\"\n",
    "    results_path = f'../models/{model_name}/{model_name}_training_results.png'\n",
    "    \n",
    "    if os.path.exists(results_path):\n",
    "        img = cv2.imread(results_path)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(img_rgb)\n",
    "        plt.title(f'{model_name.title()} Detection - Training Results')\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Training results not found for {model_name}\")\n",
    "        print(f\"Expected path: {results_path}\")\n",
    "        print(\"Train the model first to generate results.\")\n",
    "\n",
    "# Display training results for each model\n",
    "for model in models:\n",
    "    plot_training_results(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üñºÔ∏è Sample Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample images from each dataset\n",
    "def show_sample_images(model_name, num_samples=4):\n",
    "    \"\"\"Display sample images from the dataset.\"\"\"\n",
    "    images_dir = f'../{model_name}-detection/data/train/images'\n",
    "    \n",
    "    if not os.path.exists(images_dir):\n",
    "        print(f\"Images directory not found: {images_dir}\")\n",
    "        return\n",
    "    \n",
    "    image_files = glob.glob(os.path.join(images_dir, '*.jpg')) + \\\n",
    "                 glob.glob(os.path.join(images_dir, '*.png'))\n",
    "    \n",
    "    if not image_files:\n",
    "        print(f\"No images found in {images_dir}\")\n",
    "        return\n",
    "    \n",
    "    # Select random samples\n",
    "    sample_files = np.random.choice(image_files, min(num_samples, len(image_files)), replace=False)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, len(sample_files), figsize=(15, 4))\n",
    "    if len(sample_files) == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for idx, img_path in enumerate(sample_files):\n",
    "        img = cv2.imread(img_path)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        axes[idx].imshow(img_rgb)\n",
    "        axes[idx].set_title(os.path.basename(img_path))\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.suptitle(f'{model_name.title()} Detection - Sample Images')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Show samples for each model\n",
    "for model in models:\n",
    "    show_sample_images(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a comprehensive summary report\n",
    "print(\"üèôÔ∏è SMART CITY COMPUTER VISION PROJECT SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for model in models:\n",
    "    print(f\"\\n{model.upper()} DETECTION:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Dataset info\n",
    "    if model in dataset_stats:\n",
    "        stats = dataset_stats[model]\n",
    "        total_images = sum(stats.values())\n",
    "        print(f\"üìä Dataset: {total_images} total images\")\n",
    "        print(f\"  - Train: {stats.get('train', 0)}\")\n",
    "        print(f\"  - Valid: {stats.get('valid', 0)}\")\n",
    "        print(f\"  - Test: {stats.get('test', 0)}\")\n",
    "    else:\n",
    "        print(\"üìä Dataset: Not found\")\n",
    "    \n",
    "    # Model info\n",
    "    model_path = f'../models/{model}/{model}_best.pt'\n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"ü§ñ Model: Trained ‚úÖ\")\n",
    "        file_size = os.path.getsize(model_path) / (1024 * 1024)  # MB\n",
    "        print(f\"üì¶ Size: {file_size:.1f} MB\")\n",
    "    else:\n",
    "        print(f\"ü§ñ Model: Not trained ‚ùå\")\n",
    "    \n",
    "    # Classes\n",
    "    class_names = get_class_names(model)\n",
    "    print(f\"üè∑Ô∏è Classes: {list(class_names.values())}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üöÄ Ready for inference with demo.py!\")\n",
    "print(\"üìñ See README.md for usage instructions.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}